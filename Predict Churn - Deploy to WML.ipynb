{"nbformat_minor": 1, "cells": [{"source": "<table style=\"border: none\" align=\"left\">\n   <tr style=\"border: none\">\n      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Lab: Build, Save and Deploy a Model to IBM Watson Machine Learning (WML)</b></th>\n      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n   </tr>\n</table>", "cell_type": "markdown", "metadata": {}}, {"source": "\nThis notebook walks you through these steps:\n- Build a Spark ML model to predict customer churn\n- Save the model in the WML repository\n- Create a Deployment in WML\n- Invoke the deployed model with a Rest Client to test it", "cell_type": "markdown", "metadata": {}}, {"source": "### Step 1: Download the customer churn data", "cell_type": "markdown", "metadata": {}}, {"source": "#Run once to install the wget package\n!pip install wget", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "import wget\nurl_churn='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/churn.csv'\nurl_customer='https://raw.githubusercontent.com/yfphoon/dsx_demo/master/data/customer_churn/customer.csv'\n\n#remove existing files before downloading\n!rm -f churn.csv\n!rm -f customer.csv\n\nchurnFilename=wget.download(url_churn)\ncustomerFilename=wget.download(url_customer)\n\n!ls -l churn.csv\n!ls -l customer.csv", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "### Step 2: Create DataFrames with files", "cell_type": "markdown", "metadata": {}}, {"source": "churn= sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(churnFilename)\ncustomer= sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(customerFilename)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Step 3: Merge Files", "cell_type": "markdown", "metadata": {}}, {"source": "data=customer.join(churn,customer['ID']==churn['ID']).select(customer['*'],churn['CHURN'])", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Step 4: Rename some columns\nThis step is to remove spaces from columns names", "cell_type": "markdown", "metadata": {}}, {"source": "data = data.withColumnRenamed(\"Est Income\", \"EstIncome\").withColumnRenamed(\"Car Owner\",\"CarOwner\")\ndata.toPandas().head()", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "### Step 5: Build the Spark pipeline and the Random Forest model\n\"Pipeline\" is an API in SparkML that's used for building models.\nAdditional information on SparkML: https://spark.apache.org/docs/2.0.2/ml-guide.html", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, IndexToString\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# StringIndexer encodes a string column of labels to a column of label indices. \nSI1 = StringIndexer(inputCol='Gender', outputCol='GenderEncoded')\nSI2 = StringIndexer(inputCol='Status',outputCol='StatusEncoded')\nSI3 = StringIndexer(inputCol='CarOwner',outputCol='CarOwnerEncoded')\nSI4 = StringIndexer(inputCol='Paymethod',outputCol='PaymethodEncoded')\nSI5 = StringIndexer(inputCol='LocalBilltype',outputCol='LocalBilltypeEncoded')\nSI6 = StringIndexer(inputCol='LongDistanceBilltype',outputCol='LongDistanceBilltypeEncoded')\n\n# Apply OneHotEncoder so categorical features aren't given numeric importance\n# One-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. \nOH1 = OneHotEncoder(inputCol=\"GenderEncoded\", outputCol=\"GenderEncoded\"+\"classVec\")\nOH2 = OneHotEncoder(inputCol=\"StatusEncoded\", outputCol=\"StatusEncoded\"+\"classVec\")\nOH3 = OneHotEncoder(inputCol=\"CarOwnerEncoded\", outputCol=\"CarOwnerEncoded\"+\"classVec\")\nOH4 = OneHotEncoder(inputCol=\"PaymethodEncoded\", outputCol=\"PaymethodEncoded\"+\"classVec\")\nOH5 = OneHotEncoder(inputCol=\"LocalBilltypeEncoded\", outputCol=\"LocalBilltypeEncoded\"+\"classVec\")\nOH6 = OneHotEncoder(inputCol=\"LongDistanceBilltypeEncoded\", outputCol=\"LongDistanceBilltypeEncoded\"+\"classVec\")\n\n\n# Pipelines API requires that input variables are passed in  a vector\nassembler = VectorAssembler(inputCols=[\"GenderEncodedclassVec\", \"StatusEncodedclassVec\", \"CarOwnerEncodedclassVec\", \"PaymethodEncodedclassVec\", \"LocalBilltypeEncodedclassVec\", \\\n                                       \"LongDistanceBilltypeEncodedclassVec\", \"Children\", \"EstIncome\", \"Age\", \"LongDistance\", \"International\", \"Local\",\\\n                                      \"Dropped\",\"Usage\",\"RatePlan\"], outputCol=\"features\")", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# encode the label column\nlabelIndexer = StringIndexer(inputCol='CHURN', outputCol='label').fit(data)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# instantiate the algorithm, take the default settings\nrf=RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Convert indexed labels back to original labels.\nlabelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=labelIndexer.labels)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# build the pipeline\npipeline = Pipeline(stages=[SI1,SI2,SI3,SI4,SI5,SI6, labelIndexer, OH1, OH2, OH3, OH4, OH5, OH6, assembler, rf, labelConverter])# Split data into train and test datasets", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Split data into train and test datasets\n(trainingData, testingData) = data.randomSplit([0.7, 0.3],seed=9)\ntrainingData.cache()\ntestingData.cache()", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "# Build model. The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\nmodel = pipeline.fit(trainingData)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Step 6: Score the test data set", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "results = model.transform(testingData)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Step 7: Model Evaluation ", "cell_type": "markdown", "metadata": {}}, {"source": "print 'Precision model1 = {:.2f}.'.format(results.filter(results.label == results.prediction).count() / float(results.count()))", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"label\", metricName=\"areaUnderROC\")\nprint 'Area under ROC curve = {:.2f}.'.format(evaluator.evaluate(results))", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "### Step 8: Save Model in WML repository\n\nIn this section you will store your model in the Watson Machine Learning (WML) repository by using Python client libraries.\n* <a href=\"https://console.ng.bluemix.net/docs/services/PredictiveModeling/index.html\">WML Documentation</a>\n* <a href=\"http://watson-ml-api.mybluemix.net/\">WML REST API</a> \n* <a href=\"https://watson-ml-staging-libs.mybluemix.net/repository-python/\">WML Repository API</a>\n<br/>\n\nFirst, you must import client libraries.", "cell_type": "markdown", "metadata": {}}, {"source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Put your authentication information from your instance of the Watson Machine Learning service in <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> in the next cell. You can find your information in the **Service Credentials** tab of your service instance in Bluemix.\n\n![WML Credentials](https://raw.githubusercontent.com/yfphoon/IntroToWML/master/images/WML%20Credentials.png)\n\n<span style=\"color:red\">Replace the service_path and credentials with your own information</span>\n\nservice_path=[your url]<br/>\ninstance_id=[your instance_id]<br/>\nusername=[your username]<br/>\npassword=[your password]<br/>", "cell_type": "markdown", "metadata": {}}, {"source": "# @hidden_cell\nservice_path = 'https://ibm-watson-ml.mybluemix.net'\ninstance_id = 'XXXX'\nusername = 'XXXX'\npassword = 'XXXX'", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Authorize the repository client:", "cell_type": "markdown", "metadata": {}}, {"source": "ml_repository_client = MLRepositoryClient(service_path)\nml_repository_client.authorize(username, password)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Create the model artifact.\n\n<b>Tip:</b> The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the Watson Machine Learning service).\n", "cell_type": "markdown", "metadata": {}}, {"source": "model_artifact = MLRepositoryArtifact(model, training_data=trainingData, name=\"Predict Customer Churn\")", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "Save model artifact to your Watson Machine Learning instance:", "cell_type": "markdown", "metadata": {}}, {"source": "saved_model = ml_repository_client.models.save(model_artifact)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "# Print the saved model properties\nprint \"modelType: \" + saved_model.meta.prop(\"modelType\")\nprint \"creationTime: \" + str(saved_model.meta.prop(\"creationTime\"))\nprint \"modelVersionHref: \" + saved_model.meta.prop(\"modelVersionHref\")\nprint \"label: \" + saved_model.meta.prop(\"label\")", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "### Step 9: Generate the Authorization Token for Invoking the model", "cell_type": "markdown", "metadata": {}}, {"source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(username, password))\nurl = '{}/v2/identity/token'.format(service_path)\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "### Step 10:  Go to WML in Bluemix to create a Deployment Endpoint\n\n* In your <a href=\"https://console.ng.bluemix.net/dashboard/apps/\" target=\"_blank\">Bluemix</a> dashboard, click into your WML Service and click the **Launch Dashboard** button under Watson Machine Learing.\n![WML Launch Dashboard](https://raw.githubusercontent.com/yfphoon/dsx_demo/master/WML_Launch_Dashboard.png)\n\n<br/>\n* You should see your deployed model in the **Models** tab\n", "cell_type": "markdown", "metadata": {}}, {"source": "* Under *Actions*, click on the 3 ellipses and click ***Create Deployment***.  Give your deployment configuration a unique name, e.g. \"Predict Customer Churn Deply\", select Type=Online and click **Save**.\n<br/>\n<br/>\n* In the *Deployments tab*, under *Actions*, click **View Details**\n<br/>\n<br/>\n* Scoll down to **API Details**, copy the value of the **Scoring Endpoint** into your notepad.  (e.g. \thttps://ibm-watson-ml.mybluemix.net/v2/published_models/64fd0462-3f8a-4b42-820b-59a4da9b7dc6/deployments/7d9995ed-7daf-4cfd-b40f-37cb8ab3d88f/online)", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "### Step 11:  Invoke the model through REST API call", "cell_type": "markdown", "metadata": {}}, {"source": "#### Create a JSON Sample record for the model ", "cell_type": "markdown", "metadata": {}}, {"source": "sample_data = {\n    \"fields\": [\n    \"ID\",\n    \"Gender\",\n    \"Status\",\n    \"Children\",\n    \"EstIncome\",\n    \"CarOwner\",\n    \"Age\",\n    \"LongDistance\",\n    \"International\",\n    \"Local\",\n    \"Dropped\",\n    \"Paymethod\",\n    \"LocalBilltype\",\n    \"LongDistanceBilltype\",\n    \"Usage\",\n    \"RatePlan\"\n    ],\n    \"values\": [ [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000] ]\n} \n\nsample_json = json.dumps(sample_data)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "#### Option 1: Call the REST API Programmatically", "cell_type": "markdown", "metadata": {}}, {"source": "# Get the scoring endpoint from the WML service\n# Replace the value for churnModel_endpoint with your own scoring endpoint\nchurnModel_endpoint = 'https://ibm-watson-ml.mybluemix.net/v3/wml_instances/edcba09a-71fb-4078-a8a2-a4988eefdd31/published_models/092f0df7-21b4-4648-99b1-702b9f2c7a67/deployments/3e0bdba0-d364-433d-bf0b-9ac5c728e09c/online'\nheader_online = {'Content-Type': 'application/json', 'Authorization': mltoken}\n\n# API call here\nresponse_scoring = requests.post(churnModel_endpoint, data=sample_json, headers=header_online)\n\nprint response_scoring.text", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "#### Grab Predicted Value ", "cell_type": "markdown", "metadata": {}}, {"source": "wml = json.loads(response_scoring.text)\n\n# First zip the fields and values together\nzipped_wml = zip(wml['fields'], wml['values'].pop())\n\n# Next iterate through items and grab the prediction value\n[v for (k,v) in zipped_wml if k == 'prediction'].pop()", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {}}, {"source": "#### Option 2: Call the REST API through a REST Client, e.g. https://client.restlet.com/  (Note: Chrome browser works better)", "cell_type": "markdown", "metadata": {}}, {"source": "# Print the Authorization token\nprint(mltoken)", "execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true}}, {"source": "In the REST client interface enter the following information:\n\n1. Protocol:  **HTTPS**\n<br/>\n<br/>\n\n2. URI: **your scoring endpoint**  (Step 10)\n<br/>\n<br/>\n3. method: **POST**\n<br/>\n<br/>\n4. Authorization:  **your generated token**. **Hint**: Add \"Basic authorization\" with a dummy value of 1 in the userid field. Then replace the value with the token. \n<br/>\n<br/>\n5. Content Type: **application/JSON**\n<br/>\n<br/>\n6. JSON Body:<br/>**{\n  \"fields\": [\n    \"ID\",\"Gender\",\"Status\",\"Children\",\"EstIncome\",\"CarOwner\",\"Age\",\"LongDistance\",\"International\",\"Local\",\"Dropped\",\"Paymethod\",\"LocalBilltype\",\"LongDistanceBilltype\",\"Usage\",\"RatePlan\"\n  ],\n  \"values\": [ \n  [999,\"F\",\"M\",2.0,77551.100000,\"Y\",33.600000,20.530000,0.000000,41.890000,1.000000,\"CC\",\"Budget\",\"Intnl_discount\",62.420000,2.000000]\n  ]\n} **\n<br/>\n<br/>\n7. Click **Send*\n\nScroll down to the **RESPONSE** section to see the scored results\n\n**Note:** The values in the JSON body does not include the label.\n", "cell_type": "markdown", "metadata": {}}, {"source": "**Sample REST Client Input**\n![Rest Client Input](https://github.com/ibm-cloud-architecture/refarch-data-science/blob/master/static/imgs/RestRequest.PNG?raw=true)", "cell_type": "markdown", "metadata": {}}, {"source": "You have come to the end of this notebook", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "\n**Sidney Phoon**\n<br/>\nyfphoon@us.ibm.com\n<br/>\nAugust 11, 2017", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python2-spark20", "language": "python", "display_name": "Python 2 with Spark 2.0"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "name": "python", "pygments_lexer": "ipython2", "mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "2.7.11"}}}